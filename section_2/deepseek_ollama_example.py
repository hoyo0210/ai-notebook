#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeek Ollama API è°ƒç”¨ç¤ºä¾‹
é€‚ç”¨äºå·²é€šè¿‡ Ollama éƒ¨ç½²çš„ DeepSeek æ¨¡å‹
"""

import requests
import json
import time
from typing import List, Dict, Optional

class DeepSeekOllamaClient:
    """DeepSeek Ollama å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "deepseek-r1:1.5b"):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            base_url: Ollama æœåŠ¡åœ°å€ï¼Œé»˜è®¤æœ¬åœ°11434ç«¯å£
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ deepseek-r1:1.5b
        """
        self.base_url = base_url
        self.model = model
        self.api_url = f"{base_url}/api/generate"
        self.chat_url = f"{base_url}/api/chat"
    
    def check_model_status(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get('models', [])
                return any(model['name'] == self.model for model in models)
            return False
        except:
            return False
    
    def generate_text(self, prompt: str, **kwargs) -> Dict:
        """
        ç”Ÿæˆæ–‡æœ¬ï¼ˆå•æ¬¡è°ƒç”¨ï¼‰
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰
        
        Returns:
            åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸
        """
        data = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            **kwargs
        }
        
        try:
            response = requests.post(self.api_url, json=data, timeout=60)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            return {"error": f"è¯·æ±‚å¤±è´¥: {str(e)}"}
    
    def chat(self, messages: List[Dict], **kwargs) -> Dict:
        """
        å¤šè½®å¯¹è¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}, ...]
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            åŒ…å«å›å¤çš„å­—å…¸
        """
        data = {
            "model": self.model,
            "messages": messages,
            "stream": False,
            **kwargs
        }
        
        try:
            response = requests.post(self.chat_url, json=data, timeout=60)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            return {"error": f"è¯·æ±‚å¤±è´¥: {str(e)}"}
    
    def stream_generate(self, prompt: str, **kwargs):
        """
        æµå¼ç”Ÿæˆæ–‡æœ¬
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
        
        Yields:
            ç”Ÿæˆçš„å†…å®¹ç‰‡æ®µ
        """
        data = {
            "model": self.model,
            "prompt": prompt,
            "stream": True,
            **kwargs
        }
        
        try:
            response = requests.post(self.api_url, json=data, stream=True, timeout=60)
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    try:
                        chunk = json.loads(line.decode('utf-8'))
                        if 'response' in chunk:
                            yield chunk['response']
                        if chunk.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
        except requests.exceptions.RequestException as e:
            yield f"é”™è¯¯: {str(e)}"

def test_basic_functionality():
    """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹çŠ¶æ€...")
    client = DeepSeekOllamaClient()
    
    if not client.check_model_status():
        print("âŒ æ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿ï¼š")
        print("   1. Ollama æœåŠ¡å·²å¯åŠ¨")
        print("   2. DeepSeek æ¨¡å‹å·²ä¸‹è½½")
        print("   3. æœåŠ¡åœ°å€æ­£ç¡®")
        return False
    
    print("âœ… æ¨¡å‹çŠ¶æ€æ­£å¸¸")
    return True

def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ğŸš€ DeepSeek Ollama API è°ƒç”¨ç¤ºä¾‹")
    print("="*60)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = DeepSeekOllamaClient()
    
    # 1. åŸºç¡€æ–‡æœ¬ç”Ÿæˆ
    print("\nğŸ“ 1. åŸºç¡€æ–‡æœ¬ç”Ÿæˆ")
    print("-" * 30)
    result = client.generate_text(
        prompt="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½",
        temperature=0.7,
        max_tokens=100
    )
    
    if 'error' in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
    else:
        print(f"âœ… ç”Ÿæˆç»“æœ: {result.get('response', '')}")
    
    # 2. å¤šè½®å¯¹è¯
    print("\nğŸ’¬ 2. å¤šè½®å¯¹è¯")
    print("-" * 30)
    messages = [
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"},
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯DeepSeekï¼Œä¸€ä¸ªå¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ã€‚"},
        {"role": "user", "content": "ä½ èƒ½åšä»€ä¹ˆï¼Ÿ"}
    ]
    
    chat_result = client.chat(messages, temperature=0.5)
    if 'error' in chat_result:
        print(f"âŒ é”™è¯¯: {chat_result['error']}")
    else:
        print(f"âœ… å¯¹è¯å›å¤: {chat_result.get('message', {}).get('content', '')}")
    
    # 3. æµå¼ç”Ÿæˆ
    print("\nğŸŒŠ 3. æµå¼ç”Ÿæˆ")
    print("-" * 30)
    print("æ­£åœ¨ç”Ÿæˆ...")
    try:
        for chunk in client.stream_generate(
            prompt="è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—",
            temperature=0.8
        ):
            print(chunk, end='', flush=True)
        print("\nâœ… æµå¼ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ æµå¼ç”Ÿæˆé”™è¯¯: {str(e)}")

def advanced_examples():
    """é«˜çº§ç”¨æ³•ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ğŸ¯ é«˜çº§ç”¨æ³•ç¤ºä¾‹")
    print("="*60)
    
    client = DeepSeekOllamaClient()
    
    # 1. ä»£ç ç”Ÿæˆ
    print("\nğŸ’» 1. ä»£ç ç”Ÿæˆ")
    print("-" * 30)
    code_prompt = """
    è¯·ç”¨Pythonç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š
    1. æ¥æ”¶ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨
    2. ç»Ÿè®¡æ¯ä¸ªå­—ç¬¦ä¸²çš„é•¿åº¦
    3. è¿”å›é•¿åº¦å¤§äº5çš„å­—ç¬¦ä¸²åˆ—è¡¨
    4. åŒ…å«é€‚å½“çš„é”™è¯¯å¤„ç†å’Œæ–‡æ¡£å­—ç¬¦ä¸²
    """
    
    code_result = client.generate_text(
        prompt=code_prompt,
        temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ä»£ç 
        max_tokens=800
    )
    
    if 'error' in code_result:
        print(f"âŒ é”™è¯¯: {code_result['error']}")
    else:
        print("âœ… ç”Ÿæˆçš„ä»£ç :")
        print(code_result.get('response', ''))
    
    # 2. æ•°å­¦æ¨ç†
    print("\nğŸ§® 2. æ•°å­¦æ¨ç†")
    print("-" * 30)
    math_prompt = """
    è¯·è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼Œå¹¶è¯¦ç»†è¯´æ˜è§£é¢˜æ­¥éª¤ï¼š
    
    é—®é¢˜ï¼šä¸€ä¸ªé•¿æ–¹å½¢çš„é•¿æ˜¯å®½çš„2å€ï¼Œå‘¨é•¿æ˜¯30å˜ç±³ï¼Œæ±‚é•¿æ–¹å½¢çš„é¢ç§¯ã€‚
    
    è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
    1. è®¾æœªçŸ¥æ•°
    2. åˆ—æ–¹ç¨‹
    3. è§£æ–¹ç¨‹
    4. æ±‚é¢ç§¯
    5. éªŒè¯ç­”æ¡ˆ
    """
    
    math_result = client.generate_text(
        prompt=math_prompt,
        temperature=0.1,  # æ•°å­¦é—®é¢˜éœ€è¦æ›´ç²¾ç¡®çš„ç­”æ¡ˆ
        max_tokens=600
    )
    
    if 'error' in math_result:
        print(f"âŒ é”™è¯¯: {math_result['error']}")
    else:
        print("âœ… æ•°å­¦æ¨ç†ç»“æœ:")
        print(math_result.get('response', ''))
    
    # 3. è§’è‰²æ‰®æ¼”
    print("\nğŸ­ 3. è§’è‰²æ‰®æ¼”")
    print("-" * 30)
    role_prompt = """
    ä½ ç°åœ¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    - æœ‰10å¹´ä»¥ä¸Šçš„Pythonå¼€å‘ç»éªŒ
    - ç†Ÿæ‚‰Djangoã€Flaskã€FastAPIç­‰Webæ¡†æ¶
    - æ“…é•¿æ•°æ®åº“è®¾è®¡å’Œä¼˜åŒ–
    - æœ‰ä¸°å¯Œçš„é¡¹ç›®æ¶æ„ç»éªŒ
    
    è¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶æä¾›ä¸“ä¸šçš„å»ºè®®å’Œæœ€ä½³å®è·µã€‚
    
    ç”¨æˆ·é—®é¢˜ï¼šæˆ‘æƒ³å¼€å‘ä¸€ä¸ªåœ¨çº¿å•†åŸç³»ç»Ÿï¼Œåº”è¯¥é€‰æ‹©ä»€ä¹ˆæŠ€æœ¯æ ˆï¼Ÿè¯·è¯¦ç»†è¯´æ˜ç†ç”±ã€‚
    """
    
    role_result = client.generate_text(
        prompt=role_prompt,
        temperature=0.7,
        max_tokens=1000
    )
    
    if 'error' in role_result:
        print(f"âŒ é”™è¯¯: {role_result['error']}")
    else:
        print("âœ… è§’è‰²æ‰®æ¼”å›å¤:")
        print(role_result.get('response', ''))

def robust_api_call():
    """å¥å£®çš„APIè°ƒç”¨ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ğŸ›¡ï¸ å¥å£®è°ƒç”¨ç¤ºä¾‹")
    print("="*60)
    
    client = DeepSeekOllamaClient()
    max_retries = 3
    
    for attempt in range(max_retries):
        print(f"\nğŸ”„ å°è¯• {attempt + 1}/{max_retries}")
        try:
            result = client.generate_text(
                prompt="è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ",
                temperature=0.5,
                max_tokens=300
            )
            
            if 'error' not in result:
                print("âœ… å¥å£®è°ƒç”¨æˆåŠŸ")
                print(f"ç»“æœ: {result.get('response', '')}")
                break
            else:
                print(f"âŒ å°è¯•å¤±è´¥: {result['error']}")
                
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {str(e)}")
        
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt
            print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)
    else:
        print("âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")

def interactive_chat():
    """äº¤äº’å¼èŠå¤©"""
    print("\n" + "="*60)
    print("ğŸ’¬ äº¤äº’å¼èŠå¤©æ¨¡å¼")
    print("="*60)
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºèŠå¤©")
    print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("-" * 60)
    
    client = DeepSeekOllamaClient()
    messages = []
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if user_input.lower() == 'clear':
                messages = []
                print("ğŸ§¹ å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            
            if not user_input:
                continue
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": user_input})
            
            # è°ƒç”¨API
            print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
            response = client.chat(messages, temperature=0.7)
            
            if 'error' in response:
                print(f"âŒ é”™è¯¯: {response['error']}")
                continue
            
            assistant_message = response.get('message', {}).get('content', '')
            print(f"ğŸ¤– DeepSeek: {assistant_message}")
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
            messages.append({"role": "assistant", "content": assistant_message})
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ èŠå¤©å·²ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ DeepSeek Ollama API æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    if not test_basic_functionality():
        return
    
    while True:
        print("\nğŸ“‹ è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
        print("1. åŸºç¡€åŠŸèƒ½æµ‹è¯•")
        print("2. é«˜çº§ç”¨æ³•ç¤ºä¾‹")
        print("3. å¥å£®è°ƒç”¨æµ‹è¯•")
        print("4. äº¤äº’å¼èŠå¤©")
        print("5. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
        
        if choice == '1':
            example_usage()
        elif choice == '2':
            advanced_examples()
        elif choice == '3':
            robust_api_call()
        elif choice == '4':
            interactive_chat()
        elif choice == '5':
            print("ğŸ‘‹ å†è§ï¼")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main() 